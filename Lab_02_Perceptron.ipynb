{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s34836/WUM/blob/main/Lab_02_Perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iDU8DtxSJUx"
      },
      "source": [
        "# Perceptron\n",
        "Fill in the template below to finish the implementation of the Perceptron. Use the following training algorithm:\n",
        "\n",
        "1. Randomly initialize weights and bias.\n",
        "2. Repeat for a given number of iterations ('epochs'):\n",
        "    - For every training example:\n",
        "        - Calculate the output $y = f(z)$, where:\n",
        "        $$z = \\mathbf{w} \\cdot \\mathbf{x} - \\theta$$\n",
        "        $$\n",
        "            f(z)=\n",
        "            \\begin{cases}\n",
        "            1 & \\text{for } z \\geq 0 \\\\\n",
        "            0 & \\text{for } z < 0\n",
        "            \\end{cases}\n",
        "        $$\n",
        "        - Update the weights and bias:\n",
        "        $$ \\mathbf{w}' = \\mathbf{w} + \\alpha (y - \\hat{y}) \\mathbf{x} $$\n",
        "        $$ \\theta' = \\theta - \\alpha (y - \\hat{y}) $$\n",
        "\n",
        "To test your implementation, you can use a dataset of your choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0mhpE54mSJUy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, learning_rate=0.01, epochs=10, batch_size=32):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # losowa inicjalizacja wag i biasu\n",
        "        n_samples, n_features = X.shape\n",
        "        self.w = np.random.randn(n_features)\n",
        "        self.theta = np.random.randn()\n",
        "\n",
        "        # trenowanie\n",
        "        for _ in range(self.epochs):\n",
        "            for i in range(n_samples):\n",
        "                z = np.dot(self.w, X[i]) - self.theta\n",
        "                y_pred = 1 if z >= 0 else 0  # funkcja aktywacji f(z)\n",
        "                # aktualizacja wag i biasu\n",
        "                self.w += self.learning_rate * (y[i] - y_pred) * X[i]\n",
        "                self.theta -= self.learning_rate * (y[i] - y_pred)\n",
        "\n",
        "    def predict(self, X):\n",
        "        z = np.dot(X, self.w) - self.theta\n",
        "        return np.where(z >= 0, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Test na bramka AND ---\n",
        "X = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
        "y = np.array([0, 0, 0, 1])\n",
        "\n",
        "perceptron = Perceptron(learning_rate=0.05, epochs=50)\n",
        "perceptron.fit(X, y)\n",
        "\n",
        "preds = perceptron.predict(X)\n",
        "print(\"Predictions:\", preds)\n",
        "print(\"Expected:   \", y)\n",
        "print(\"Weights:\", perceptron.w)\n",
        "print(\"Theta (bias):\", perceptron.theta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_H_nhwweS9tW",
        "outputId": "c8c13f5e-94c6-477c-a3d7-e7fcf80d7b1b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [0 0 0 1]\n",
            "Expected:    [0 0 0 1]\n",
            "Weights: [0.06040476 1.31611363]\n",
            "Theta (bias): 1.3460332271132345\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Test na bramka OR ---\n",
        "X = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
        "y = np.array([0, 1, 1, 1])\n",
        "\n",
        "perceptron = Perceptron(learning_rate=0.05, epochs=50)\n",
        "perceptron.fit(X, y)\n",
        "\n",
        "preds = perceptron.predict(X)\n",
        "print(\"Predictions:\", preds)\n",
        "print(\"Expected:   \", y)\n",
        "print(\"Weights:\", perceptron.w)\n",
        "print(\"Theta (bias):\", perceptron.theta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XOEJnF1ThLV",
        "outputId": "e79925b9-2b60-4703-adde-b8d4b4f1dd6c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [1 1 1 1]\n",
            "Expected:    [0 1 1 1]\n",
            "Weights: [ 0.07454646 -0.16383663]\n",
            "Theta (bias): -0.16711182311554879\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target  # 0 = malignant, 1 = benign\n",
        "\n",
        "# --- Skalowanie i podzia≈Ç na train/test ---\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=1\n",
        ")\n",
        "\n",
        "# --- Trening perceptronu ---\n",
        "perceptron = Perceptron(learning_rate=0.01, epochs=500)\n",
        "perceptron.fit(X_train, y_train)\n",
        "\n",
        "# --- Predykcje i ocena ---\n",
        "y_pred = perceptron.predict(X_test)\n",
        "accuracy = np.mean(y_pred == y_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Weights:\", perceptron.w)\n",
        "print(\"Theta (bias):\", perceptron.theta)"
      ],
      "metadata": {
        "id": "Ymh9fu5mLY5Q",
        "outputId": "f3832fba-3c92-4860-f1c9-8eeb74130682",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9649122807017544\n",
            "Weights: [ 1.22535877  0.05148691  0.27082081 -0.50895133 -0.23998102  0.19555233\n",
            " -0.11404558 -0.63984548  0.28002587  0.1112748  -0.57081758  0.13495909\n",
            "  0.22296573 -0.09552314 -0.01676358 -0.2340859   0.2728351  -0.51230789\n",
            "  0.07762691  0.63513411  0.03002323 -0.29836929  0.42543264 -2.55384409\n",
            "  0.11355275  0.72953585 -0.70109479  0.138228   -0.36302587 -0.68737762]\n",
            "Theta (bias): 0.4014385176205686\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}