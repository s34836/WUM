{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s34836/WUM/blob/main/Lab_02_Perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iDU8DtxSJUx"
      },
      "source": [
        "# Perceptron\n",
        "Fill in the template below to finish the implementation of the Perceptron. Use the following training algorithm:\n",
        "\n",
        "1. Randomly initialize weights and bias.\n",
        "2. Repeat for a given number of iterations ('epochs'):\n",
        "    - For every training example:\n",
        "        - Calculate the output $y = f(z)$, where:\n",
        "        $$z = \\mathbf{w} \\cdot \\mathbf{x} - \\theta$$\n",
        "        $$\n",
        "            f(z)=\n",
        "            \\begin{cases}\n",
        "            1 & \\text{for } z \\geq 0 \\\\\n",
        "            0 & \\text{for } z < 0\n",
        "            \\end{cases}\n",
        "        $$\n",
        "        - Update the weights and bias:\n",
        "        $$ \\mathbf{w}' = \\mathbf{w} + \\alpha (y - \\hat{y}) \\mathbf{x} $$\n",
        "        $$ \\theta' = \\theta - \\alpha (y - \\hat{y}) $$\n",
        "\n",
        "To test your implementation, you can use a dataset of your choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mhpE54mSJUy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, learning_rate=0.01, epochs=10, batch_size=32):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # losowa inicjalizacja wag i biasu (Î¸)\n",
        "        n_samples, n_features = X.shape\n",
        "        self.w = np.random.randn(n_features)\n",
        "        self.theta = np.random.randn()\n",
        "\n",
        "        # trenowanie\n",
        "        for _ in range(self.epochs):\n",
        "            for i in range(n_samples):\n",
        "                z = np.dot(self.w, X[i]) - self.theta\n",
        "                y_pred = 1 if z >= 0 else 0  # funkcja aktywacji f(z)\n",
        "                # aktualizacja wag i biasu\n",
        "                self.w += self.learning_rate * (y[i] - y_pred) * X[i]\n",
        "                self.theta -= self.learning_rate * (y[i] - y_pred)\n",
        "\n",
        "    def predict(self, X):\n",
        "        z = np.dot(X, self.w) - self.theta\n",
        "        return np.where(z >= 0, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Test na bramka AND ---\n",
        "X = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
        "y = np.array([0, 0, 0, 1])\n",
        "\n",
        "perceptron = Perceptron(learning_rate=0.05, epochs=50)\n",
        "perceptron.fit(X, y)\n",
        "\n",
        "preds = perceptron.predict(X)\n",
        "print(\"Predictions:\", preds)\n",
        "print(\"Expected:   \", y)\n",
        "print(\"Weights:\", perceptron.w)\n",
        "print(\"Theta (bias):\", perceptron.theta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_H_nhwweS9tW",
        "outputId": "fc2627de-6bd0-4e3e-b9b7-ea03929565ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [0 0 0 1]\n",
            "Expected:    [0 0 0 1]\n",
            "Weights: [0.10898919 0.08067953]\n",
            "Theta (bias): 0.15112250359442686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Test na bramka OR ---\n",
        "X = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
        "y = np.array([0, 1, 1, 1])\n",
        "\n",
        "perceptron = Perceptron(learning_rate=0.05, epochs=50)\n",
        "perceptron.fit(X, y)\n",
        "\n",
        "preds = perceptron.predict(X)\n",
        "print(\"Predictions:\", preds)\n",
        "print(\"Expected:   \", y)\n",
        "print(\"Weights:\", perceptron.w)\n",
        "print(\"Theta (bias):\", perceptron.theta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XOEJnF1ThLV",
        "outputId": "e9f7a352-ab35-4b46-eff5-d513f911fb79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [0 1 1 1]\n",
            "Expected:    [0 1 1 1]\n",
            "Weights: [1.68258871 0.0062099 ]\n",
            "Theta (bias): 0.005773846376267863\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}